{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [1., 0.],\n",
      "        [2., 1.],\n",
      "        [0., 2.]], requires_grad=True)\n",
      "tensor([[-1.2500,  1.0000,  0.0000,  0.2500],\n",
      "        [ 1.0000, -1.8333,  0.6667,  0.1667],\n",
      "        [ 0.0000,  0.6667, -0.8333,  0.1667],\n",
      "        [ 0.2500,  0.1667,  0.1667, -0.5833]], grad_fn=<CopySlices>)\n",
      "tensor(12., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import math\n",
    "from scipy.spatial import ConvexHull\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_triangulation (points, triang):\n",
    "    plt.triplot (points[:,0], points[:,1], triang)\n",
    "    plt.plot (points[:,0], points[:,1], 'o')\n",
    "    plt.show()\n",
    "\n",
    "def calc_L (points, simplices):\n",
    "    #simplices = Delaunay (points).simplices\n",
    "    #distances = euclidean_distances (points, points)\n",
    "    \n",
    "    L = torch.zeros((len(points), len(points)))\n",
    "\n",
    "    for sim in simplices:\n",
    "        for ind in [[0, 1], [1, 2], [0, 2]]:\n",
    "            #L [sim [ind [0]], sim [ind [1]]] = distances [sim [ind [0]], sim [ind [1]]]\n",
    "            #L [sim [ind [1]], sim [ind [0]]] = distances [sim [ind [1]], sim [ind [0]]]\n",
    "            L [sim [ind [0]], sim [ind [1]]] = ((points[sim [ind [0]]][0]-points[sim [ind [1]]][0])**2+\\\n",
    "                                               (points[sim [ind [0]]][1]-points[sim [ind [1]]][1])**2)**0.5\n",
    "            L [sim [ind [1]], sim [ind [0]]] = ((points[sim [ind [0]]][0]-points[sim [ind [1]]][0])**2+\\\n",
    "                                               (points[sim [ind [0]]][1]-points[sim [ind [1]]][1])**2)**0.5\n",
    "\n",
    "    return L\n",
    "\n",
    "def calc_triangle_area (L, i1, i2, i3):\n",
    "    l1 = L [i1, i2]\n",
    "    l2 = L [i2, i3]\n",
    "    l3 = L [i3, i1]\n",
    "\n",
    "    p = (l1 + l2 + l3) / 2\n",
    "\n",
    "    return math.sqrt (p * (p - l1) * (p - l2) * (p - l3))\n",
    "\n",
    "def calc_A (simplices, L, points_num):\n",
    "    A = torch.zeros ((points_num, points_num))\n",
    "    \n",
    "    for i in range (points_num):\n",
    "        area = 0\n",
    "        \n",
    "        for j in range (len (simplices)):\n",
    "            if (i in simplices [j]):\n",
    "                sim = simplices [j]\n",
    "                \n",
    "                area_part = calc_triangle_area (L, sim [0], sim [1], sim [2])\n",
    "                \n",
    "                area += area_part / 3\n",
    "        \n",
    "        A [i, i] = area\n",
    "    \n",
    "    return A\n",
    "\n",
    "def find_E_Eb (points, simplices):\n",
    "    E = []\n",
    "    \n",
    "    for sim in simplices:\n",
    "        E.append (sorted ((sim [0], sim [1])))\n",
    "        E.append (sorted ((sim [1], sim [2])))\n",
    "        E.append (sorted ((sim [2], sim [0])))\n",
    "    \n",
    "    E_b = []\n",
    "    hull = ConvexHull (points).vertices\n",
    "    \n",
    "    for i in range (len (hull) - 1):\n",
    "        E_b.append (sorted ((hull [i], hull [i + 1])))\n",
    "    \n",
    "    E_b.append (sorted ((hull [0], hull [-1])))\n",
    "    \n",
    "    #АЛАРМА\n",
    "    #Тут нужно оставить в E и E_b только уникальные таплы.\n",
    "    #Я попробовал это сделать, но с unhashable type какая-то морока, так то я забил.\n",
    "    #В этом месте числа внутри тапла отсортированы.\n",
    "    #Пробовал вот таким образом:\n",
    "    #return list (set (E)), list (set (E_b))\n",
    "    \n",
    "    return E, E_b\n",
    "\n",
    "def calc_W (E, E_b, A, L, simplices):\n",
    "    W = torch.zeros (A.shape)\n",
    "    \n",
    "    sh = W.shape\n",
    "    \n",
    "    for i in range (sh [0]):\n",
    "        for j in range (i + 1, sh [0]):\n",
    "            kh_list = []\n",
    "    \n",
    "            for sim in simplices:\n",
    "                elem = set (sim)                \n",
    "                ele = set ([i, j])\n",
    "                \n",
    "                #print (\"ele, elem\")\n",
    "                #print (ele, elem)\n",
    "                \n",
    "                if (ele.issubset (elem)):\n",
    "                    kh_list.append (elem.difference (ele))\n",
    "            \n",
    "            if (len (kh_list) == 0):\n",
    "                continue\n",
    "            \n",
    "            h = list (kh_list [0]) [0]\n",
    "            \n",
    "            if ([i, j] in E and [i, j] not in E_b):\n",
    "                k = list (kh_list [1]) [0]\n",
    "                \n",
    "                val = 0\n",
    "                \n",
    "                val += (- L [i, j]**2 + L [j, k]**2 + L [k, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, k))\n",
    "\n",
    "                val += (- L [i, j]**2 + L [j, h]**2 + L [h, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, h))\n",
    "                \n",
    "                W [i, j] = val\n",
    "                \n",
    "            elif ([i, j] in E_b):\n",
    "                val = 0\n",
    "                \n",
    "                val += (- L [i, j]**2 + L [j, h]**2 + L [h, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, h))\n",
    "                \n",
    "                W [i, j] = val\n",
    "        \n",
    "    for i in range (sh [0]):\n",
    "        for j in range (i, sh [0]):\n",
    "            W [j] [i] = W [i] [j]\n",
    "    \n",
    "    for i in range (sh [0]):\n",
    "        W [i, i] = - sum (W [i, :])\n",
    "\n",
    "    return W\n",
    "\n",
    "def find_eigenvalues (W, A):\n",
    "    product = torch.inverse (A) @ W\n",
    "    \n",
    "    #lambdas, vectors = tuple (torch.symeig (product, eigenvectors=True))\n",
    "    lambdas, vectors = tuple (torch.eig (product, eigenvectors=True))\n",
    "    \n",
    "    return lambdas#, vectors\n",
    "\n",
    "def cut (val):\n",
    "    return (min (0, val))**2\n",
    "\n",
    "def rho (V, L, E_b, simplices):\n",
    "    rho_1 = 0\n",
    "    \n",
    "    for e in E_b:\n",
    "        rho_1 += L [e [0], e [1]]**2\n",
    "    \n",
    "    rho_2 = 0\n",
    "    \n",
    "    for s in simplices:\n",
    "        for sim in list(itertools.permutations(s)):\n",
    "\n",
    "            rot_matr = torch.tensor ([[0., -1.], [1., 0.]])\n",
    "            sub_1 = V [sim [1]] - V [sim [0]]\n",
    "            sub_2 = V [sim [2]] - V [sim [0]]\n",
    "\n",
    "            curr_val = (rot_matr @ sub_1).transpose(0, -1) @ sub_2\n",
    "\n",
    "            rho_2 += curr_val\n",
    "    \n",
    "    rho = rho_1 + cut (rho_2)\n",
    "    \n",
    "    return rho\n",
    "\n",
    "def weighted_norm (a, b):\n",
    "    norm = 0\n",
    "    \n",
    "    for i in range (len (a)):\n",
    "        norm += (a [i] - b [i])**2 / (i + 1)\n",
    "    \n",
    "    return norm\n",
    "\n",
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.0)]\n",
    "points = torch.tensor(initial, requires_grad=True)\n",
    "\n",
    "#points = np.array([[0, 0], [1, 0], [2, 0], [0, 2]])\n",
    "    \n",
    "#points = np.random.rand (6, 2)\n",
    "\n",
    "print (points)\n",
    "\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "\n",
    "L = calc_L (points, simplices)\n",
    "#print (L)\n",
    "\n",
    "A = calc_A (simplices, L, len (points))\n",
    "\n",
    "#print (A)\n",
    "\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "\n",
    "#print (E)\n",
    "#print (\"\\n\")\n",
    "#print (E_b)\n",
    "\n",
    "W = calc_W (E, E_b, A, L, simplices)\n",
    "\n",
    "print (W)\n",
    "\n",
    "pen = rho (points, L, E_b, simplices)\n",
    "\n",
    "print (pen)\n",
    "\n",
    "#plot_triangulation (points, simplices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_eigenvalues(W, A).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3000,  0.6000],\n",
       "        [-1.5000,  3.4000],\n",
       "        [-0.4667, -0.2667],\n",
       "        [ 1.6667, -3.7333]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3], [0, 3], [0, 1], [1, 3], [1, 2], [2, 3]] [[0, 3], [0, 1], [1, 2], [2, 3]]\n"
     ]
    }
   ],
   "source": [
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.0)]\n",
    "\n",
    "target = torch.tensor(initial)\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "L = calc_L (target, simplices)\n",
    "A = calc_A (simplices, L, len (points))\n",
    "W = calc_W (E, E_b, A, L, simplices)\n",
    "mu = find_eigenvalues(W, A)[:,0]\n",
    "print (E, E_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.1176e+00, -3.9372e+00, -1.6124e-07, -1.4452e+00],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "the derivative for 'eig' is not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-2e902b0c9b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_eigen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear previous gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# compute gradients of all variables wrt loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zenv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: the derivative for 'eig' is not implemented"
     ]
    }
   ],
   "source": [
    "#initial = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\n",
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 1.0)]\n",
    "\n",
    "points = torch.tensor(initial, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([points], lr = 0.000001)\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "\n",
    "for _ in range (10000):\n",
    "    L = calc_L (points, simplices)\n",
    "    A = calc_A (simplices, L, len (points))\n",
    "    W = calc_W (E, E_b, A, L, simplices)\n",
    "    pen = rho (points, L, E_b, simplices)\n",
    "    \n",
    "    current_eigen = find_eigenvalues(W, A)[:,0]\n",
    "    \n",
    "    #loss =   weighted_norm(current_eigen, mu)+pen# calculate loss\n",
    "    loss =   weighted_norm(current_eigen, mu)+pen# calculate loss\n",
    "    print (current_eigen)\n",
    "    optimizer.zero_grad()  # clear previous gradients\n",
    "    loss.backward()        # compute gradients of all variables wrt loss\n",
    "\n",
    "    optimizer.step()\n",
    "    print (current_eigen)\n",
    "    #print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
