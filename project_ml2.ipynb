{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [1., 0.],\n",
      "        [2., 1.],\n",
      "        [0., 2.]], requires_grad=True)\n",
      "tensor([[-1.2500,  1.0000,  0.0000,  0.2500],\n",
      "        [ 1.0000, -1.8333,  0.6667,  0.1667],\n",
      "        [ 0.0000,  0.6667, -0.8333,  0.1667],\n",
      "        [ 0.2500,  0.1667,  0.1667, -0.5833]], grad_fn=<CopySlices>)\n",
      "tensor(12., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import math\n",
    "from scipy.spatial import ConvexHull\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "def plot_triangulation (points, triang):\n",
    "    plt.triplot (points[:,0], points[:,1], triang)\n",
    "    plt.plot (points[:,0], points[:,1], 'o')\n",
    "    plt.show()\n",
    "\n",
    "def calc_L (points, simplices):\n",
    "    #simplices = Delaunay (points).simplices\n",
    "    #distances = euclidean_distances (points, points)\n",
    "    \n",
    "    L = torch.zeros((len(points), len(points)))\n",
    "\n",
    "    for sim in simplices:\n",
    "        for ind in [[0, 1], [1, 2], [0, 2]]:\n",
    "            #L [sim [ind [0]], sim [ind [1]]] = distances [sim [ind [0]], sim [ind [1]]]\n",
    "            #L [sim [ind [1]], sim [ind [0]]] = distances [sim [ind [1]], sim [ind [0]]]\n",
    "            L [sim [ind [0]], sim [ind [1]]] = ((points[sim [ind [0]]][0]-points[sim [ind [1]]][0])**2+\\\n",
    "                                               (points[sim [ind [0]]][1]-points[sim [ind [1]]][1])**2)**0.5\n",
    "            L [sim [ind [1]], sim [ind [0]]] = ((points[sim [ind [0]]][0]-points[sim [ind [1]]][0])**2+\\\n",
    "                                               (points[sim [ind [0]]][1]-points[sim [ind [1]]][1])**2)**0.5\n",
    "\n",
    "    return L\n",
    "\n",
    "def calc_triangle_area (L, i1, i2, i3):\n",
    "    l1 = L [i1, i2]\n",
    "    l2 = L [i2, i3]\n",
    "    l3 = L [i3, i1]\n",
    "\n",
    "    p = (l1 + l2 + l3) / 2\n",
    "\n",
    "    return math.sqrt (p * (p - l1) * (p - l2) * (p - l3))\n",
    "\n",
    "def calc_A (simplices, L, points_num):\n",
    "    A = torch.zeros ((points_num, points_num))\n",
    "    \n",
    "    for i in range (points_num):\n",
    "        area = 0\n",
    "        \n",
    "        for j in range (len (simplices)):\n",
    "            if (i in simplices [j]):\n",
    "                sim = simplices [j]\n",
    "                \n",
    "                area_part = calc_triangle_area (L, sim [0], sim [1], sim [2])\n",
    "                \n",
    "                area += area_part / 3\n",
    "        \n",
    "        A [i, i] = area\n",
    "    \n",
    "    return A\n",
    "\n",
    "def find_E_Eb (points, simplices):\n",
    "    E = []\n",
    "    \n",
    "    for sim in simplices:\n",
    "        E.append (sorted ((sim [0], sim [1])))\n",
    "        E.append (sorted ((sim [1], sim [2])))\n",
    "        E.append (sorted ((sim [2], sim [0])))\n",
    "    \n",
    "    E_b = []\n",
    "    hull = ConvexHull (points).vertices\n",
    "    \n",
    "    for i in range (len (hull) - 1):\n",
    "        E_b.append (sorted ((hull [i], hull [i + 1])))\n",
    "    \n",
    "    E_b.append (sorted ((hull [0], hull [-1])))\n",
    "    \n",
    "    #АЛАРМА\n",
    "    #Тут нужно оставить в E и E_b только уникальные таплы.\n",
    "    #Я попробовал это сделать, но с unhashable type какая-то морока, так то я забил.\n",
    "    #В этом месте числа внутри тапла отсортированы.\n",
    "    #Пробовал вот таким образом:\n",
    "    #return list (set (E)), list (set (E_b))\n",
    "    \n",
    "    return E, E_b\n",
    "\n",
    "def calc_W (E, E_b, A, L, simplices):\n",
    "    W = torch.zeros (A.shape)\n",
    "    \n",
    "    sh = W.shape\n",
    "    \n",
    "    for i in range (sh [0]):\n",
    "        for j in range (i + 1, sh [0]):\n",
    "            kh_list = []\n",
    "    \n",
    "            for sim in simplices:\n",
    "                elem = set (sim)                \n",
    "                ele = set ([i, j])\n",
    "                \n",
    "                #print (\"ele, elem\")\n",
    "                #print (ele, elem)\n",
    "                \n",
    "                if (ele.issubset (elem)):\n",
    "                    kh_list.append (elem.difference (ele))\n",
    "            \n",
    "            if (len (kh_list) == 0):\n",
    "                continue\n",
    "            \n",
    "            h = list (kh_list [0]) [0]\n",
    "            \n",
    "            if ([i, j] in E and [i, j] not in E_b):\n",
    "                k = list (kh_list [1]) [0]\n",
    "                \n",
    "                val = 0\n",
    "                \n",
    "                val += (- L [i, j]**2 + L [j, k]**2 + L [k, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, k))\n",
    "\n",
    "                val += (- L [i, j]**2 + L [j, h]**2 + L [h, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, h))\n",
    "                \n",
    "                W [i, j] = val\n",
    "                \n",
    "            elif ([i, j] in E_b):\n",
    "                val = 0\n",
    "                \n",
    "                val += (- L [i, j]**2 + L [j, h]**2 + L [h, i]**2) / \\\n",
    "                    (8 * calc_triangle_area (L, i, j, h))\n",
    "                \n",
    "                W [i, j] = val\n",
    "        \n",
    "    for i in range (sh [0]):\n",
    "        for j in range (i, sh [0]):\n",
    "            W [j] [i] = W [i] [j]\n",
    "    \n",
    "    for i in range (sh [0]):\n",
    "        W [i, i] = - sum (W [i, :])\n",
    "\n",
    "    return W\n",
    "\n",
    "def find_eig (A):\n",
    "    n, m = A.shape\n",
    "\n",
    "    #Q = np.eye(n)\n",
    "    #R = A.astype(np.float64).copy()\n",
    "    \n",
    "    Q = torch.eye (n)\n",
    "    R = A.clone ()\n",
    "    \n",
    "    for i in range(m):\n",
    "        x = R[i:, i].clone()\n",
    "        \n",
    "        #u = x[:, np.newaxis]\n",
    "        u = x.unsqueeze (1)\n",
    "        \n",
    "        #alpha = np.linalg.norm(u)\n",
    "        alpha = u.detach().numpy()\n",
    "        \n",
    "        u[0] -= alpha\n",
    "        v = u / np.linalg.norm(u)\n",
    "        \n",
    "        H = np.eye(n - i) - 2 * v.dot(v.conj().T)\n",
    "        \n",
    "        H = np.concatenate([np.zeros([n - i, i]), H], axis=1)\n",
    "        H = np.concatenate([np.eye(i, n), H], axis=0)\n",
    "\n",
    "        R = H.dot(R)\n",
    "        Q = Q.dot(H)\n",
    "\n",
    "    #return Q[:, :m], R[:m]\n",
    "    \n",
    "    eigs = []\n",
    "    \n",
    "    for i in range (n):\n",
    "        eigs.append (R [i, i])\n",
    "    \n",
    "    return eigs\n",
    "\n",
    "def modified_gram_schmidt_qr(A): # 5 pts\n",
    "    Q = torch.zeros((A.shape[0], A.shape[1])) #saaas\n",
    "    R = torch.zeros((A.shape[1], A.shape[1]))\n",
    "    \n",
    "    #initialization\n",
    "    Q[:, :A.shape[1]] = A[:, :A.shape[1]].clone()\n",
    "    \n",
    "    #Q building with G-S ortagonalization\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(i):\n",
    "            Q[:, i] = Q[:, i].clone()-Q[:, i].clone() @ Q[:, j].clone()*Q[:, j].clone()\n",
    "        shit1 = torch.norm(Q[:, i]).clone()\n",
    "        shit2 = Q[:, i].clone()/shit1\n",
    "        Q[:, i] = shit2.clone()\n",
    "    \n",
    "    #R building\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(i+1):\n",
    "            R[j, i] = Q[:, j].clone() @(A[:, i]).clone()\n",
    "    \n",
    "    return Q, R\n",
    "\n",
    "def modified_gram_schmidt_qr_(A): # 5 pts\n",
    "    assert A.shape[0] >= A.shape[1], 'm is not >= n'\n",
    "    new_vectors = torch.zeros(A.shape)\n",
    "    for i in range(A.shape[1]):\n",
    "        new_vectors[:,i] += A[:,i]\n",
    "        if i > 0:\n",
    "            new_vectors[:,i] -= torch.tensor(((A[:,i] @ new_vectors[:,0])/(new_vectors[:,0] @ new_vectors[:,0])) * new_vectors[:,0])\n",
    "        \n",
    "        for j in range(1,i):\n",
    "            new_vectors[:,i] -= torch.tensor(((new_vectors[:,i] @ new_vectors[:,j])/(new_vectors[:,j] @ new_vectors[:,j])) * new_vectors[:,j])\n",
    "        \n",
    "    # normalization\n",
    "    for i in range(new_vectors.shape[1]):\n",
    "        new_vectors[:,i] /= torch.tensor(new_vectors[:,i]).norm()\n",
    "    Q = new_vectors\n",
    "    R = torch.zeros((A.shape[1],A.shape[1]))\n",
    "    for i in range(A.shape[1]):\n",
    "        for j in range(i, A.shape[1]):\n",
    "            R[i,j] += A[:,j] @ new_vectors[:,i]\n",
    "    return Q, R\n",
    "\n",
    "def find_eigenvalues (W, A):\n",
    "    product = torch.inverse(a) @ \\\n",
    "W\n",
    "    #lambdas, vectors = tuple (torch.symeig (product, eigenvectors=True))\n",
    "    #lambdas, vectors = tuple (torch.eig (product, eigenvectors=True))\n",
    "\n",
    "    Q, R = modified_gram_schmidt_qr_ (product)\n",
    "    \n",
    "    eigen = torch.diag(R)\n",
    "    #eigen[-1]=0\n",
    "    \n",
    "    return eigen#, vectors\n",
    "\n",
    "def cut (val):\n",
    "    return (min (0, val))**2\n",
    "\n",
    "def rho (V, L, E_b, simplices):\n",
    "    rho_1 = 0\n",
    "    \n",
    "    for e in E_b:\n",
    "        rho_1 += L [e [0], e [1]]**2\n",
    "    \n",
    "    rho_2 = 0\n",
    "    \n",
    "    for s in simplices:\n",
    "        for sim in list(itertools.permutations(s)):\n",
    "\n",
    "            rot_matr = torch.tensor ([[0., -1.], [1., 0.]])\n",
    "            sub_1 = V [sim [1]] - V [sim [0]]\n",
    "            sub_2 = V [sim [2]] - V [sim [0]]\n",
    "\n",
    "            curr_val = (rot_matr @ sub_1).transpose(0, -1) @ sub_2\n",
    "\n",
    "            rho_2 += curr_val\n",
    "    \n",
    "    rho = rho_1 + cut (rho_2)\n",
    "    \n",
    "    return rho\n",
    "\n",
    "def weighted_norm (a, b):\n",
    "    norm = 0\n",
    "    \n",
    "    for i in range (len (a)):\n",
    "        norm += (a [i] - b [i])**2 / (i + 1)\n",
    "    \n",
    "    return norm\n",
    "\n",
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.0)]\n",
    "points = torch.tensor(initial, requires_grad=True)\n",
    "\n",
    "#points = np.array([[0, 0], [1, 0], [2, 0], [0, 2]])\n",
    "    \n",
    "#points = np.random.rand (6, 2)\n",
    "\n",
    "print (points)\n",
    "\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "\n",
    "L = calc_L (points, simplices)\n",
    "#print (L)\n",
    "\n",
    "A = calc_A (simplices, L, len (points))\n",
    "\n",
    "#print (A)\n",
    "\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "\n",
    "#print (E)\n",
    "#print (\"\\n\")\n",
    "#print (E_b)\n",
    "\n",
    "W = calc_W (E, E_b, A, L, simplices)\n",
    "\n",
    "print (W)\n",
    "\n",
    "pen = rho (points, L, E_b, simplices)\n",
    "\n",
    "print (pen)\n",
    "\n",
    "#plot_triangulation (points, simplices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = torch.inverse (A) @ W\n",
    "    \n",
    "    #lambdas, vectors = tuple (torch.symeig (product, eigenvectors=True))\n",
    "    #lambdas, vectors = tuple (torch.eig (product, eigenvectors=True))\n",
    "\n",
    "Q, R = modified_gram_schmidt_qr (product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.9487,  1.8415,  0.8187, -0.7330], grad_fn=<DiagBackward>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9497, -0.1771, -0.0572,  0.2520],\n",
       "         [ 0.3039, -0.6167, -0.3613,  0.6299],\n",
       "         [ 0.0000,  0.7241, -0.5770,  0.3780],\n",
       "         [ 0.0760,  0.2531,  0.7303,  0.6299]], grad_fn=<QrBackward>),\n",
       " tensor([[ 3.9487e+00, -3.5024e+00,  2.5831e-01, -7.0466e-01],\n",
       "         [ 0.0000e+00,  1.8415e+00, -1.6495e+00, -1.9198e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  8.1867e-01, -8.1867e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3842e-07]],\n",
       "        grad_fn=<QrBackward>))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.qr(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_getri_single is not implemented for type torch.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-b3fb475831a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_A\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msimplices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_W\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimplices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_eigenvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-280-2393065390b4>\u001b[0m in \u001b[0;36mfind_eigenvalues\u001b[0;34m(W, A)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_eigenvalues\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;31m#lambdas, vectors = tuple (torch.symeig (product, eigenvectors=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _th_getri_single is not implemented for type torch.LongTensor"
     ]
    }
   ],
   "source": [
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.0)]\n",
    "\n",
    "#initial = torch.rand (15, 2)\n",
    "\n",
    "target = torch.tensor(initial)\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "L = calc_L (target, simplices)\n",
    "A = calc_A (simplices, L, len (points))\n",
    "W = calc_W (E, E_b, A, L, simplices)\n",
    "mu = find_eigenvalues(W, A)\n",
    "print (E, E_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kefir/miniconda3/envs/zenv/lib/python3.7/site-packages/ipykernel_launcher.py:205: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/kefir/miniconda3/envs/zenv/lib/python3.7/site-packages/ipykernel_launcher.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/kefir/miniconda3/envs/zenv/lib/python3.7/site-packages/ipykernel_launcher.py:212: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23700.9727, grad_fn=<AddBackward0>)\n",
      "tensor(23688.1543, grad_fn=<AddBackward0>)\n",
      "tensor(23698.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23645.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23629.1230, grad_fn=<AddBackward0>)\n",
      "tensor(23617.7246, grad_fn=<AddBackward0>)\n",
      "tensor(23632.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23715.7422, grad_fn=<AddBackward0>)\n",
      "tensor(23685.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23639.2773, grad_fn=<AddBackward0>)\n",
      "tensor(23636.9805, grad_fn=<AddBackward0>)\n",
      "tensor(23670.9531, grad_fn=<AddBackward0>)\n",
      "tensor(23638.9297, grad_fn=<AddBackward0>)\n",
      "tensor(23726.6504, grad_fn=<AddBackward0>)\n",
      "tensor(23706.2148, grad_fn=<AddBackward0>)\n",
      "tensor(23725.0586, grad_fn=<AddBackward0>)\n",
      "tensor(23732.3340, grad_fn=<AddBackward0>)\n",
      "tensor(23642.6895, grad_fn=<AddBackward0>)\n",
      "tensor(23634.3027, grad_fn=<AddBackward0>)\n",
      "tensor(23672.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23694.8945, grad_fn=<AddBackward0>)\n",
      "tensor(23718.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23683.6582, grad_fn=<AddBackward0>)\n",
      "tensor(23667.6133, grad_fn=<AddBackward0>)\n",
      "tensor(23737.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23663.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23732.2305, grad_fn=<AddBackward0>)\n",
      "tensor(23663.8613, grad_fn=<AddBackward0>)\n",
      "tensor(23723.1523, grad_fn=<AddBackward0>)\n",
      "tensor(23717.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23732.8027, grad_fn=<AddBackward0>)\n",
      "tensor(23749.7188, grad_fn=<AddBackward0>)\n",
      "tensor(23678.0547, grad_fn=<AddBackward0>)\n",
      "tensor(23679.0508, grad_fn=<AddBackward0>)\n",
      "tensor(23664.0938, grad_fn=<AddBackward0>)\n",
      "tensor(23676.6797, grad_fn=<AddBackward0>)\n",
      "tensor(23756.6875, grad_fn=<AddBackward0>)\n",
      "tensor(23746.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23752.2852, grad_fn=<AddBackward0>)\n",
      "tensor(23728.3398, grad_fn=<AddBackward0>)\n",
      "tensor(23678.7695, grad_fn=<AddBackward0>)\n",
      "tensor(23723.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23752.6113, grad_fn=<AddBackward0>)\n",
      "tensor(23678.1113, grad_fn=<AddBackward0>)\n",
      "tensor(23676.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23739.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23745.1875, grad_fn=<AddBackward0>)\n",
      "tensor(23726.3867, grad_fn=<AddBackward0>)\n",
      "tensor(23744.4434, grad_fn=<AddBackward0>)\n",
      "tensor(23683.3281, grad_fn=<AddBackward0>)\n",
      "tensor(23704.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23761.2402, grad_fn=<AddBackward0>)\n",
      "tensor(23753.9434, grad_fn=<AddBackward0>)\n",
      "tensor(23736.6250, grad_fn=<AddBackward0>)\n",
      "tensor(23689.5117, grad_fn=<AddBackward0>)\n",
      "tensor(23757.9746, grad_fn=<AddBackward0>)\n",
      "tensor(23697.2949, grad_fn=<AddBackward0>)\n",
      "tensor(23742.1094, grad_fn=<AddBackward0>)\n",
      "tensor(23692.2285, grad_fn=<AddBackward0>)\n",
      "tensor(23778.1992, grad_fn=<AddBackward0>)\n",
      "tensor(23690.1094, grad_fn=<AddBackward0>)\n",
      "tensor(23684.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23775.7852, grad_fn=<AddBackward0>)\n",
      "tensor(23785.7578, grad_fn=<AddBackward0>)\n",
      "tensor(23706.0605, grad_fn=<AddBackward0>)\n",
      "tensor(23771.8320, grad_fn=<AddBackward0>)\n",
      "tensor(23780.7578, grad_fn=<AddBackward0>)\n",
      "tensor(23690.2363, grad_fn=<AddBackward0>)\n",
      "tensor(23707.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23699.0312, grad_fn=<AddBackward0>)\n",
      "tensor(23739.2246, grad_fn=<AddBackward0>)\n",
      "tensor(23794.3496, grad_fn=<AddBackward0>)\n",
      "tensor(23781.8242, grad_fn=<AddBackward0>)\n",
      "tensor(23770.7422, grad_fn=<AddBackward0>)\n",
      "tensor(23701.4375, grad_fn=<AddBackward0>)\n",
      "tensor(23796.2969, grad_fn=<AddBackward0>)\n",
      "tensor(23768.0117, grad_fn=<AddBackward0>)\n",
      "tensor(23774.6992, grad_fn=<AddBackward0>)\n",
      "tensor(23731.9902, grad_fn=<AddBackward0>)\n",
      "tensor(23707.5254, grad_fn=<AddBackward0>)\n",
      "tensor(23761.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23707.5371, grad_fn=<AddBackward0>)\n",
      "tensor(23712.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23709.2891, grad_fn=<AddBackward0>)\n",
      "tensor(23788.6777, grad_fn=<AddBackward0>)\n",
      "tensor(23807.1016, grad_fn=<AddBackward0>)\n",
      "tensor(23719.4023, grad_fn=<AddBackward0>)\n",
      "tensor(23732.5039, grad_fn=<AddBackward0>)\n",
      "tensor(23762.7969, grad_fn=<AddBackward0>)\n",
      "tensor(23808.8418, grad_fn=<AddBackward0>)\n",
      "tensor(23775.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23810.6211, grad_fn=<AddBackward0>)\n",
      "tensor(23720.8848, grad_fn=<AddBackward0>)\n",
      "tensor(23806.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23732.9961, grad_fn=<AddBackward0>)\n",
      "tensor(23809.7734, grad_fn=<AddBackward0>)\n",
      "tensor(23794.9629, grad_fn=<AddBackward0>)\n",
      "tensor(23724.8066, grad_fn=<AddBackward0>)\n",
      "tensor(23822.0078, grad_fn=<AddBackward0>)\n",
      "tensor(23823.0508, grad_fn=<AddBackward0>)\n",
      "tensor(23824.2734, grad_fn=<AddBackward0>)\n",
      "tensor(23733.6113, grad_fn=<AddBackward0>)\n",
      "tensor(23736.7207, grad_fn=<AddBackward0>)\n",
      "tensor(23787.4199, grad_fn=<AddBackward0>)\n",
      "tensor(23755.9160, grad_fn=<AddBackward0>)\n",
      "tensor(23826.0117, grad_fn=<AddBackward0>)\n",
      "tensor(23771.6172, grad_fn=<AddBackward0>)\n",
      "tensor(23731.5430, grad_fn=<AddBackward0>)\n",
      "tensor(23741.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23820.3613, grad_fn=<AddBackward0>)\n",
      "tensor(23800.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23749.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23831.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23755.4863, grad_fn=<AddBackward0>)\n",
      "tensor(23760.5898, grad_fn=<AddBackward0>)\n",
      "tensor(23755.0820, grad_fn=<AddBackward0>)\n",
      "tensor(23842.4844, grad_fn=<AddBackward0>)\n",
      "tensor(23829.9395, grad_fn=<AddBackward0>)\n",
      "tensor(23754.8516, grad_fn=<AddBackward0>)\n",
      "tensor(23843.1367, grad_fn=<AddBackward0>)\n",
      "tensor(23840.4785, grad_fn=<AddBackward0>)\n",
      "tensor(23742.0391, grad_fn=<AddBackward0>)\n",
      "tensor(23741.1562, grad_fn=<AddBackward0>)\n",
      "tensor(23843.6875, grad_fn=<AddBackward0>)\n",
      "tensor(23756.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23768.8418, grad_fn=<AddBackward0>)\n",
      "tensor(23775.7188, grad_fn=<AddBackward0>)\n",
      "tensor(23839.2852, grad_fn=<AddBackward0>)\n",
      "tensor(23835.2480, grad_fn=<AddBackward0>)\n",
      "tensor(23767.0078, grad_fn=<AddBackward0>)\n",
      "tensor(23832.7812, grad_fn=<AddBackward0>)\n",
      "tensor(23845.5762, grad_fn=<AddBackward0>)\n",
      "tensor(23822.9824, grad_fn=<AddBackward0>)\n",
      "tensor(23831.2461, grad_fn=<AddBackward0>)\n",
      "tensor(23853.8809, grad_fn=<AddBackward0>)\n",
      "tensor(23846.1484, grad_fn=<AddBackward0>)\n",
      "tensor(23763.9082, grad_fn=<AddBackward0>)\n",
      "tensor(23843.7715, grad_fn=<AddBackward0>)\n",
      "tensor(23754.6445, grad_fn=<AddBackward0>)\n",
      "tensor(23794.5703, grad_fn=<AddBackward0>)\n",
      "tensor(23794.7773, grad_fn=<AddBackward0>)\n",
      "tensor(23755.3398, grad_fn=<AddBackward0>)\n",
      "tensor(23785.5332, grad_fn=<AddBackward0>)\n",
      "tensor(23760.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23862.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23768.1680, grad_fn=<AddBackward0>)\n",
      "tensor(23862.7773, grad_fn=<AddBackward0>)\n",
      "tensor(23832.4512, grad_fn=<AddBackward0>)\n",
      "tensor(23824.5293, grad_fn=<AddBackward0>)\n",
      "tensor(23859.9219, grad_fn=<AddBackward0>)\n",
      "tensor(23803.2695, grad_fn=<AddBackward0>)\n",
      "tensor(23853.3535, grad_fn=<AddBackward0>)\n",
      "tensor(23877.2070, grad_fn=<AddBackward0>)\n",
      "tensor(23775.1309, grad_fn=<AddBackward0>)\n",
      "tensor(23866.7285, grad_fn=<AddBackward0>)\n",
      "tensor(23798.4844, grad_fn=<AddBackward0>)\n",
      "tensor(23777.3008, grad_fn=<AddBackward0>)\n",
      "tensor(23879.4355, grad_fn=<AddBackward0>)\n",
      "tensor(23778.7207, grad_fn=<AddBackward0>)\n",
      "tensor(23790.1387, grad_fn=<AddBackward0>)\n",
      "tensor(23808.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23868.9668, grad_fn=<AddBackward0>)\n",
      "tensor(23839.6816, grad_fn=<AddBackward0>)\n",
      "tensor(23880.8281, grad_fn=<AddBackward0>)\n",
      "tensor(23780.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23786.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23858.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23802.4688, grad_fn=<AddBackward0>)\n",
      "tensor(23895.3926, grad_fn=<AddBackward0>)\n",
      "tensor(23786.5723, grad_fn=<AddBackward0>)\n",
      "tensor(23880.9590, grad_fn=<AddBackward0>)\n",
      "tensor(23782.7734, grad_fn=<AddBackward0>)\n",
      "tensor(23878.1953, grad_fn=<AddBackward0>)\n",
      "tensor(23879.9570, grad_fn=<AddBackward0>)\n",
      "tensor(23889.2598, grad_fn=<AddBackward0>)\n",
      "tensor(23859.8652, grad_fn=<AddBackward0>)\n",
      "tensor(23789.0039, grad_fn=<AddBackward0>)\n",
      "tensor(23891.2910, grad_fn=<AddBackward0>)\n",
      "tensor(23796.8535, grad_fn=<AddBackward0>)\n",
      "tensor(23903.0859, grad_fn=<AddBackward0>)\n",
      "tensor(23834.7441, grad_fn=<AddBackward0>)\n",
      "tensor(23790.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23865.1816, grad_fn=<AddBackward0>)\n",
      "tensor(23793.0469, grad_fn=<AddBackward0>)\n",
      "tensor(23801.4297, grad_fn=<AddBackward0>)\n",
      "tensor(23865.6250, grad_fn=<AddBackward0>)\n",
      "tensor(23911.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23794.6289, grad_fn=<AddBackward0>)\n",
      "tensor(23908.5469, grad_fn=<AddBackward0>)\n",
      "tensor(23812.1602, grad_fn=<AddBackward0>)\n",
      "tensor(23815.1777, grad_fn=<AddBackward0>)\n",
      "tensor(23883.9961, grad_fn=<AddBackward0>)\n",
      "tensor(23911.1074, grad_fn=<AddBackward0>)\n",
      "tensor(23904.4043, grad_fn=<AddBackward0>)\n",
      "tensor(23909.2129, grad_fn=<AddBackward0>)\n",
      "tensor(23910.6328, grad_fn=<AddBackward0>)\n",
      "tensor(23908.9961, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23914.5020, grad_fn=<AddBackward0>)\n",
      "tensor(23800.8203, grad_fn=<AddBackward0>)\n",
      "tensor(23880.5176, grad_fn=<AddBackward0>)\n",
      "tensor(23832.5879, grad_fn=<AddBackward0>)\n",
      "tensor(23854.6367, grad_fn=<AddBackward0>)\n",
      "tensor(23907.7188, grad_fn=<AddBackward0>)\n",
      "tensor(23829.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23807.3613, grad_fn=<AddBackward0>)\n",
      "tensor(23872.8848, grad_fn=<AddBackward0>)\n",
      "tensor(23913.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23914.3066, grad_fn=<AddBackward0>)\n",
      "tensor(23819.9336, grad_fn=<AddBackward0>)\n",
      "tensor(23910.4121, grad_fn=<AddBackward0>)\n",
      "tensor(23923.9609, grad_fn=<AddBackward0>)\n",
      "tensor(23912.8555, grad_fn=<AddBackward0>)\n",
      "tensor(23875.7500, grad_fn=<AddBackward0>)\n",
      "tensor(23859.3555, grad_fn=<AddBackward0>)\n",
      "tensor(23816.6621, grad_fn=<AddBackward0>)\n",
      "tensor(23890.7441, grad_fn=<AddBackward0>)\n",
      "tensor(23827.8477, grad_fn=<AddBackward0>)\n",
      "tensor(23865.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23881.6641, grad_fn=<AddBackward0>)\n",
      "tensor(23922.3945, grad_fn=<AddBackward0>)\n",
      "tensor(23901.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23825.4785, grad_fn=<AddBackward0>)\n",
      "tensor(23841.9023, grad_fn=<AddBackward0>)\n",
      "tensor(23927.9121, grad_fn=<AddBackward0>)\n",
      "tensor(23812.1934, grad_fn=<AddBackward0>)\n",
      "tensor(23898.2773, grad_fn=<AddBackward0>)\n",
      "tensor(23930.1445, grad_fn=<AddBackward0>)\n",
      "tensor(23815.9590, grad_fn=<AddBackward0>)\n",
      "tensor(23932.4941, grad_fn=<AddBackward0>)\n",
      "tensor(23866.0742, grad_fn=<AddBackward0>)\n",
      "tensor(23928.5410, grad_fn=<AddBackward0>)\n",
      "tensor(23820.9727, grad_fn=<AddBackward0>)\n",
      "tensor(23837.3770, grad_fn=<AddBackward0>)\n",
      "tensor(23839.4121, grad_fn=<AddBackward0>)\n",
      "tensor(23817.9609, grad_fn=<AddBackward0>)\n",
      "tensor(23814.3320, grad_fn=<AddBackward0>)\n",
      "tensor(23844.6074, grad_fn=<AddBackward0>)\n",
      "tensor(23923.1152, grad_fn=<AddBackward0>)\n",
      "tensor(23935.5977, grad_fn=<AddBackward0>)\n",
      "tensor(23853.8711, grad_fn=<AddBackward0>)\n",
      "tensor(23900.2793, grad_fn=<AddBackward0>)\n",
      "tensor(23857.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23820.0430, grad_fn=<AddBackward0>)\n",
      "tensor(23941.3848, grad_fn=<AddBackward0>)\n",
      "tensor(23836.1367, grad_fn=<AddBackward0>)\n",
      "tensor(23950.7207, grad_fn=<AddBackward0>)\n",
      "tensor(23955.1289, grad_fn=<AddBackward0>)\n",
      "tensor(23831.2305, grad_fn=<AddBackward0>)\n",
      "tensor(23952.7051, grad_fn=<AddBackward0>)\n",
      "tensor(23881.0547, grad_fn=<AddBackward0>)\n",
      "tensor(23891.6973, grad_fn=<AddBackward0>)\n",
      "tensor(23823.8125, grad_fn=<AddBackward0>)\n",
      "tensor(23837.2246, grad_fn=<AddBackward0>)\n",
      "tensor(23831.5547, grad_fn=<AddBackward0>)\n",
      "tensor(23935.0840, grad_fn=<AddBackward0>)\n",
      "tensor(23829.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23946.2012, grad_fn=<AddBackward0>)\n",
      "tensor(23938.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23877.0059, grad_fn=<AddBackward0>)\n",
      "tensor(23834.1582, grad_fn=<AddBackward0>)\n",
      "tensor(23934.2246, grad_fn=<AddBackward0>)\n",
      "tensor(23883.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23957.5684, grad_fn=<AddBackward0>)\n",
      "tensor(23938.9531, grad_fn=<AddBackward0>)\n",
      "tensor(23961.8027, grad_fn=<AddBackward0>)\n",
      "tensor(23937.4219, grad_fn=<AddBackward0>)\n",
      "tensor(23947.3242, grad_fn=<AddBackward0>)\n",
      "tensor(23839.6230, grad_fn=<AddBackward0>)\n",
      "tensor(23957.1445, grad_fn=<AddBackward0>)\n",
      "tensor(23837.2461, grad_fn=<AddBackward0>)\n",
      "tensor(23964.1738, grad_fn=<AddBackward0>)\n",
      "tensor(23917.1777, grad_fn=<AddBackward0>)\n",
      "tensor(23833.2148, grad_fn=<AddBackward0>)\n",
      "tensor(23939.4062, grad_fn=<AddBackward0>)\n",
      "tensor(23837.0781, grad_fn=<AddBackward0>)\n",
      "tensor(23841.0020, grad_fn=<AddBackward0>)\n",
      "tensor(23961.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23837.0918, grad_fn=<AddBackward0>)\n",
      "tensor(23953.8301, grad_fn=<AddBackward0>)\n",
      "tensor(23843.5098, grad_fn=<AddBackward0>)\n",
      "tensor(23965.0312, grad_fn=<AddBackward0>)\n",
      "tensor(23873.3301, grad_fn=<AddBackward0>)\n",
      "tensor(23844.5469, grad_fn=<AddBackward0>)\n",
      "tensor(23933.6426, grad_fn=<AddBackward0>)\n",
      "tensor(23899.0801, grad_fn=<AddBackward0>)\n",
      "tensor(23931.8809, grad_fn=<AddBackward0>)\n",
      "tensor(23970.7656, grad_fn=<AddBackward0>)\n",
      "tensor(23969.4102, grad_fn=<AddBackward0>)\n",
      "tensor(23913.4961, grad_fn=<AddBackward0>)\n",
      "tensor(23973.9375, grad_fn=<AddBackward0>)\n",
      "tensor(23956.0547, grad_fn=<AddBackward0>)\n",
      "tensor(23948.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23890.7227, grad_fn=<AddBackward0>)\n",
      "tensor(23886.8867, grad_fn=<AddBackward0>)\n",
      "tensor(23910.2422, grad_fn=<AddBackward0>)\n",
      "tensor(23860.9082, grad_fn=<AddBackward0>)\n",
      "tensor(23876.2266, grad_fn=<AddBackward0>)\n",
      "tensor(23857.7070, grad_fn=<AddBackward0>)\n",
      "tensor(23951.7832, grad_fn=<AddBackward0>)\n",
      "tensor(23853.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23977.4375, grad_fn=<AddBackward0>)\n",
      "tensor(23866.9355, grad_fn=<AddBackward0>)\n",
      "tensor(23975.5957, grad_fn=<AddBackward0>)\n",
      "tensor(23945.2090, grad_fn=<AddBackward0>)\n",
      "tensor(23965.1016, grad_fn=<AddBackward0>)\n",
      "tensor(23980.6621, grad_fn=<AddBackward0>)\n",
      "tensor(23950.2148, grad_fn=<AddBackward0>)\n",
      "tensor(23972.6309, grad_fn=<AddBackward0>)\n",
      "tensor(23948.0742, grad_fn=<AddBackward0>)\n",
      "tensor(23935.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23959.5957, grad_fn=<AddBackward0>)\n",
      "tensor(23869.2832, grad_fn=<AddBackward0>)\n",
      "tensor(23986.0059, grad_fn=<AddBackward0>)\n",
      "tensor(23855.8301, grad_fn=<AddBackward0>)\n",
      "tensor(23867.2402, grad_fn=<AddBackward0>)\n",
      "tensor(23955.8984, grad_fn=<AddBackward0>)\n",
      "tensor(23981.6660, grad_fn=<AddBackward0>)\n",
      "tensor(23862.4082, grad_fn=<AddBackward0>)\n",
      "tensor(23912.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23857.3984, grad_fn=<AddBackward0>)\n",
      "tensor(23985.8730, grad_fn=<AddBackward0>)\n",
      "tensor(23959.7090, grad_fn=<AddBackward0>)\n",
      "tensor(23906.9375, grad_fn=<AddBackward0>)\n",
      "tensor(23904.2559, grad_fn=<AddBackward0>)\n",
      "tensor(23976.2129, grad_fn=<AddBackward0>)\n",
      "tensor(23901.5449, grad_fn=<AddBackward0>)\n",
      "tensor(23960.6465, grad_fn=<AddBackward0>)\n",
      "tensor(23971.2480, grad_fn=<AddBackward0>)\n",
      "tensor(23902.9590, grad_fn=<AddBackward0>)\n",
      "tensor(23870.0527, grad_fn=<AddBackward0>)\n",
      "tensor(23913.5605, grad_fn=<AddBackward0>)\n",
      "tensor(23867.9980, grad_fn=<AddBackward0>)\n",
      "tensor(23906.8926, grad_fn=<AddBackward0>)\n",
      "tensor(23975.0410, grad_fn=<AddBackward0>)\n",
      "tensor(23858.4512, grad_fn=<AddBackward0>)\n",
      "tensor(23878.4980, grad_fn=<AddBackward0>)\n",
      "tensor(23972.4922, grad_fn=<AddBackward0>)\n",
      "tensor(23859.5117, grad_fn=<AddBackward0>)\n",
      "tensor(23937.3965, grad_fn=<AddBackward0>)\n",
      "tensor(23976.3359, grad_fn=<AddBackward0>)\n",
      "tensor(23879.3848, grad_fn=<AddBackward0>)\n",
      "tensor(23877.8848, grad_fn=<AddBackward0>)\n",
      "tensor(23905.0469, grad_fn=<AddBackward0>)\n",
      "tensor(23897.9570, grad_fn=<AddBackward0>)\n",
      "tensor(23940.7441, grad_fn=<AddBackward0>)\n",
      "tensor(24003., grad_fn=<AddBackward0>)\n",
      "tensor(23941.8613, grad_fn=<AddBackward0>)\n",
      "tensor(23966.2734, grad_fn=<AddBackward0>)\n",
      "tensor(23942.6035, grad_fn=<AddBackward0>)\n",
      "tensor(23873.2812, grad_fn=<AddBackward0>)\n",
      "tensor(23949.6777, grad_fn=<AddBackward0>)\n",
      "tensor(23928.3848, grad_fn=<AddBackward0>)\n",
      "tensor(23870.7070, grad_fn=<AddBackward0>)\n",
      "tensor(23994.6895, grad_fn=<AddBackward0>)\n",
      "tensor(23873.1406, grad_fn=<AddBackward0>)\n",
      "tensor(23863.9473, grad_fn=<AddBackward0>)\n",
      "tensor(23883.3770, grad_fn=<AddBackward0>)\n",
      "tensor(23963.7148, grad_fn=<AddBackward0>)\n",
      "tensor(23906.3887, grad_fn=<AddBackward0>)\n",
      "tensor(23962.2266, grad_fn=<AddBackward0>)\n",
      "tensor(23896.9336, grad_fn=<AddBackward0>)\n",
      "tensor(23876.7148, grad_fn=<AddBackward0>)\n",
      "tensor(23880.6484, grad_fn=<AddBackward0>)\n",
      "tensor(23915.3340, grad_fn=<AddBackward0>)\n",
      "tensor(23936.7500, grad_fn=<AddBackward0>)\n",
      "tensor(23895.2207, grad_fn=<AddBackward0>)\n",
      "tensor(23967.8223, grad_fn=<AddBackward0>)\n",
      "tensor(23884.4648, grad_fn=<AddBackward0>)\n",
      "tensor(23969.4707, grad_fn=<AddBackward0>)\n",
      "tensor(23920.0840, grad_fn=<AddBackward0>)\n",
      "tensor(23947.8828, grad_fn=<AddBackward0>)\n",
      "tensor(23880.1816, grad_fn=<AddBackward0>)\n",
      "tensor(23883.8457, grad_fn=<AddBackward0>)\n",
      "tensor(23955.9121, grad_fn=<AddBackward0>)\n",
      "tensor(23979.7617, grad_fn=<AddBackward0>)\n",
      "tensor(24017.7793, grad_fn=<AddBackward0>)\n",
      "tensor(23900.4082, grad_fn=<AddBackward0>)\n",
      "tensor(23876.6934, grad_fn=<AddBackward0>)\n",
      "tensor(24020.2871, grad_fn=<AddBackward0>)\n",
      "tensor(23981.3945, grad_fn=<AddBackward0>)\n",
      "tensor(23993.5371, grad_fn=<AddBackward0>)\n",
      "tensor(23912.2188, grad_fn=<AddBackward0>)\n",
      "tensor(23911.1680, grad_fn=<AddBackward0>)\n",
      "tensor(23893.3340, grad_fn=<AddBackward0>)\n",
      "tensor(23897.0195, grad_fn=<AddBackward0>)\n",
      "tensor(24019.2090, grad_fn=<AddBackward0>)\n",
      "tensor(24018.7500, grad_fn=<AddBackward0>)\n",
      "tensor(23941.2363, grad_fn=<AddBackward0>)\n",
      "tensor(23952.0176, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23911.8262, grad_fn=<AddBackward0>)\n",
      "tensor(24009.3223, grad_fn=<AddBackward0>)\n",
      "tensor(23926.4141, grad_fn=<AddBackward0>)\n",
      "tensor(23923.4004, grad_fn=<AddBackward0>)\n",
      "tensor(23904.1445, grad_fn=<AddBackward0>)\n",
      "tensor(23889.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23939.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23952.5176, grad_fn=<AddBackward0>)\n",
      "tensor(23930.6660, grad_fn=<AddBackward0>)\n",
      "tensor(24007.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23896.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23881.5371, grad_fn=<AddBackward0>)\n",
      "tensor(23949.4824, grad_fn=<AddBackward0>)\n",
      "tensor(23902.6895, grad_fn=<AddBackward0>)\n",
      "tensor(23916.9492, grad_fn=<AddBackward0>)\n",
      "tensor(23889.7812, grad_fn=<AddBackward0>)\n",
      "tensor(23918.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23982.9531, grad_fn=<AddBackward0>)\n",
      "tensor(23952.1191, grad_fn=<AddBackward0>)\n",
      "tensor(23950.0488, grad_fn=<AddBackward0>)\n",
      "tensor(23893.8145, grad_fn=<AddBackward0>)\n",
      "tensor(24029.4902, grad_fn=<AddBackward0>)\n",
      "tensor(23930.3516, grad_fn=<AddBackward0>)\n",
      "tensor(23999.2793, grad_fn=<AddBackward0>)\n",
      "tensor(23911.6445, grad_fn=<AddBackward0>)\n",
      "tensor(24011.5996, grad_fn=<AddBackward0>)\n",
      "tensor(24026.2637, grad_fn=<AddBackward0>)\n",
      "tensor(23899.7422, grad_fn=<AddBackward0>)\n",
      "tensor(23917.4648, grad_fn=<AddBackward0>)\n",
      "tensor(23988.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23901.3535, grad_fn=<AddBackward0>)\n",
      "tensor(23970.6660, grad_fn=<AddBackward0>)\n",
      "tensor(23924.6621, grad_fn=<AddBackward0>)\n",
      "tensor(24026.8125, grad_fn=<AddBackward0>)\n",
      "tensor(24036.1113, grad_fn=<AddBackward0>)\n",
      "tensor(24026.4277, grad_fn=<AddBackward0>)\n",
      "tensor(23919.6328, grad_fn=<AddBackward0>)\n",
      "tensor(23922.9902, grad_fn=<AddBackward0>)\n",
      "tensor(23902.8457, grad_fn=<AddBackward0>)\n",
      "tensor(24003.3301, grad_fn=<AddBackward0>)\n",
      "tensor(24038.1895, grad_fn=<AddBackward0>)\n",
      "tensor(23992.5312, grad_fn=<AddBackward0>)\n",
      "tensor(23920.6309, grad_fn=<AddBackward0>)\n",
      "tensor(24012.9395, grad_fn=<AddBackward0>)\n",
      "tensor(23911.6504, grad_fn=<AddBackward0>)\n",
      "tensor(23981.7402, grad_fn=<AddBackward0>)\n",
      "tensor(24023.0078, grad_fn=<AddBackward0>)\n",
      "tensor(23964.5137, grad_fn=<AddBackward0>)\n",
      "tensor(23918.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23927.2188, grad_fn=<AddBackward0>)\n",
      "tensor(23900.9121, grad_fn=<AddBackward0>)\n",
      "tensor(24038.0586, grad_fn=<AddBackward0>)\n",
      "tensor(24036.6035, grad_fn=<AddBackward0>)\n",
      "tensor(24045.3262, grad_fn=<AddBackward0>)\n",
      "tensor(24017.6602, grad_fn=<AddBackward0>)\n",
      "tensor(23942.6738, grad_fn=<AddBackward0>)\n",
      "tensor(24029.2227, grad_fn=<AddBackward0>)\n",
      "tensor(23915.6855, grad_fn=<AddBackward0>)\n",
      "tensor(24020.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23991.3594, grad_fn=<AddBackward0>)\n",
      "tensor(23986.4375, grad_fn=<AddBackward0>)\n",
      "tensor(24008.5586, grad_fn=<AddBackward0>)\n",
      "tensor(23980.2793, grad_fn=<AddBackward0>)\n",
      "tensor(24024.2695, grad_fn=<AddBackward0>)\n",
      "tensor(23916.9102, grad_fn=<AddBackward0>)\n",
      "tensor(23999.6094, grad_fn=<AddBackward0>)\n",
      "tensor(24048.1582, grad_fn=<AddBackward0>)\n",
      "tensor(23911.4883, grad_fn=<AddBackward0>)\n",
      "tensor(23899.0391, grad_fn=<AddBackward0>)\n",
      "tensor(23919.1562, grad_fn=<AddBackward0>)\n",
      "tensor(23904.2812, grad_fn=<AddBackward0>)\n",
      "tensor(24023.3809, grad_fn=<AddBackward0>)\n",
      "tensor(23901.8281, grad_fn=<AddBackward0>)\n",
      "tensor(23906.9082, grad_fn=<AddBackward0>)\n",
      "tensor(23952.3184, grad_fn=<AddBackward0>)\n",
      "tensor(24023.8105, grad_fn=<AddBackward0>)\n",
      "tensor(24018.6973, grad_fn=<AddBackward0>)\n",
      "tensor(23905.5898, grad_fn=<AddBackward0>)\n",
      "tensor(23938.0059, grad_fn=<AddBackward0>)\n",
      "tensor(24041.3926, grad_fn=<AddBackward0>)\n",
      "tensor(24009.0020, grad_fn=<AddBackward0>)\n",
      "tensor(23976.3613, grad_fn=<AddBackward0>)\n",
      "tensor(23940.7070, grad_fn=<AddBackward0>)\n",
      "tensor(23980.1953, grad_fn=<AddBackward0>)\n",
      "tensor(24053.6914, grad_fn=<AddBackward0>)\n",
      "tensor(23968.3496, grad_fn=<AddBackward0>)\n",
      "tensor(23914.7324, grad_fn=<AddBackward0>)\n",
      "tensor(24049.3438, grad_fn=<AddBackward0>)\n",
      "tensor(24054.9609, grad_fn=<AddBackward0>)\n",
      "tensor(23917.0039, grad_fn=<AddBackward0>)\n",
      "tensor(23909.5059, grad_fn=<AddBackward0>)\n",
      "tensor(23939.0586, grad_fn=<AddBackward0>)\n",
      "tensor(23916.9883, grad_fn=<AddBackward0>)\n",
      "tensor(23982.5391, grad_fn=<AddBackward0>)\n",
      "tensor(23928.4414, grad_fn=<AddBackward0>)\n",
      "tensor(23948.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23908.2676, grad_fn=<AddBackward0>)\n",
      "tensor(24051.0156, grad_fn=<AddBackward0>)\n",
      "tensor(24051.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24027.2148, grad_fn=<AddBackward0>)\n",
      "tensor(24051.0332, grad_fn=<AddBackward0>)\n",
      "tensor(23917.2832, grad_fn=<AddBackward0>)\n",
      "tensor(23971.0371, grad_fn=<AddBackward0>)\n",
      "tensor(23976.6016, grad_fn=<AddBackward0>)\n",
      "tensor(23914.1074, grad_fn=<AddBackward0>)\n",
      "tensor(24034.7109, grad_fn=<AddBackward0>)\n",
      "tensor(23911.3633, grad_fn=<AddBackward0>)\n",
      "tensor(23931.8242, grad_fn=<AddBackward0>)\n",
      "tensor(23931.1523, grad_fn=<AddBackward0>)\n",
      "tensor(23910.1484, grad_fn=<AddBackward0>)\n",
      "tensor(24065.1367, grad_fn=<AddBackward0>)\n",
      "tensor(24045.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23920.4062, grad_fn=<AddBackward0>)\n",
      "tensor(23959.8008, grad_fn=<AddBackward0>)\n",
      "tensor(24054.5938, grad_fn=<AddBackward0>)\n",
      "tensor(24034.6641, grad_fn=<AddBackward0>)\n",
      "tensor(24067.7656, grad_fn=<AddBackward0>)\n",
      "tensor(24041.2578, grad_fn=<AddBackward0>)\n",
      "tensor(24069.5918, grad_fn=<AddBackward0>)\n",
      "tensor(24062.0020, grad_fn=<AddBackward0>)\n",
      "tensor(24012.4766, grad_fn=<AddBackward0>)\n",
      "tensor(23971.5801, grad_fn=<AddBackward0>)\n",
      "tensor(24068.3242, grad_fn=<AddBackward0>)\n",
      "tensor(23929.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23913.1992, grad_fn=<AddBackward0>)\n",
      "tensor(24054.3789, grad_fn=<AddBackward0>)\n",
      "tensor(24009.7324, grad_fn=<AddBackward0>)\n",
      "tensor(24022.7422, grad_fn=<AddBackward0>)\n",
      "tensor(24063.7402, grad_fn=<AddBackward0>)\n",
      "tensor(24010.1875, grad_fn=<AddBackward0>)\n",
      "tensor(23988.3984, grad_fn=<AddBackward0>)\n",
      "tensor(24054.1562, grad_fn=<AddBackward0>)\n",
      "tensor(23950.5977, grad_fn=<AddBackward0>)\n",
      "tensor(24063.1055, grad_fn=<AddBackward0>)\n",
      "tensor(23924.4336, grad_fn=<AddBackward0>)\n",
      "tensor(23957.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23993.7793, grad_fn=<AddBackward0>)\n",
      "tensor(24071.3320, grad_fn=<AddBackward0>)\n",
      "tensor(24073.7559, grad_fn=<AddBackward0>)\n",
      "tensor(24028.0039, grad_fn=<AddBackward0>)\n",
      "tensor(24043.8750, grad_fn=<AddBackward0>)\n",
      "tensor(23958.7227, grad_fn=<AddBackward0>)\n",
      "tensor(24062.2422, grad_fn=<AddBackward0>)\n",
      "tensor(23918.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23990.9238, grad_fn=<AddBackward0>)\n",
      "tensor(23947.9023, grad_fn=<AddBackward0>)\n",
      "tensor(24022.9395, grad_fn=<AddBackward0>)\n",
      "tensor(23939.5820, grad_fn=<AddBackward0>)\n",
      "tensor(23992.9531, grad_fn=<AddBackward0>)\n",
      "tensor(24026.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24045.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23940.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23922.7617, grad_fn=<AddBackward0>)\n",
      "tensor(24004.4355, grad_fn=<AddBackward0>)\n",
      "tensor(24038.7695, grad_fn=<AddBackward0>)\n",
      "tensor(23993.4434, grad_fn=<AddBackward0>)\n",
      "tensor(23918.5391, grad_fn=<AddBackward0>)\n",
      "tensor(24022.2715, grad_fn=<AddBackward0>)\n",
      "tensor(23989.4688, grad_fn=<AddBackward0>)\n",
      "tensor(23984.9219, grad_fn=<AddBackward0>)\n",
      "tensor(23924.2168, grad_fn=<AddBackward0>)\n",
      "tensor(24052.5898, grad_fn=<AddBackward0>)\n",
      "tensor(23982.5391, grad_fn=<AddBackward0>)\n",
      "tensor(24002.8418, grad_fn=<AddBackward0>)\n",
      "tensor(24030.7832, grad_fn=<AddBackward0>)\n",
      "tensor(24007.0234, grad_fn=<AddBackward0>)\n",
      "tensor(24077.0996, grad_fn=<AddBackward0>)\n",
      "tensor(24038.9316, grad_fn=<AddBackward0>)\n",
      "tensor(23994.3496, grad_fn=<AddBackward0>)\n",
      "tensor(24064.5801, grad_fn=<AddBackward0>)\n",
      "tensor(24064.7402, grad_fn=<AddBackward0>)\n",
      "tensor(23920.5059, grad_fn=<AddBackward0>)\n",
      "tensor(24001.4180, grad_fn=<AddBackward0>)\n",
      "tensor(23933.3555, grad_fn=<AddBackward0>)\n",
      "tensor(23949.2969, grad_fn=<AddBackward0>)\n",
      "tensor(23926.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23952.4219, grad_fn=<AddBackward0>)\n",
      "tensor(24008.8789, grad_fn=<AddBackward0>)\n",
      "tensor(24079.2637, grad_fn=<AddBackward0>)\n",
      "tensor(23988.9668, grad_fn=<AddBackward0>)\n",
      "tensor(23949.1016, grad_fn=<AddBackward0>)\n",
      "tensor(23967.2168, grad_fn=<AddBackward0>)\n",
      "tensor(23919.7598, grad_fn=<AddBackward0>)\n",
      "tensor(23921.8555, grad_fn=<AddBackward0>)\n",
      "tensor(23999.0918, grad_fn=<AddBackward0>)\n",
      "tensor(24090.1758, grad_fn=<AddBackward0>)\n",
      "tensor(23998.1367, grad_fn=<AddBackward0>)\n",
      "tensor(24064.5781, grad_fn=<AddBackward0>)\n",
      "tensor(24040.3125, grad_fn=<AddBackward0>)\n",
      "tensor(23973.9863, grad_fn=<AddBackward0>)\n",
      "tensor(24069.9141, grad_fn=<AddBackward0>)\n",
      "tensor(23962.7188, grad_fn=<AddBackward0>)\n",
      "tensor(24041.7012, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24082.2598, grad_fn=<AddBackward0>)\n",
      "tensor(23990.8633, grad_fn=<AddBackward0>)\n",
      "tensor(23985.9883, grad_fn=<AddBackward0>)\n",
      "tensor(23960.5801, grad_fn=<AddBackward0>)\n",
      "tensor(23946.3906, grad_fn=<AddBackward0>)\n",
      "tensor(24048.9297, grad_fn=<AddBackward0>)\n",
      "tensor(24016.5527, grad_fn=<AddBackward0>)\n",
      "tensor(23975.6562, grad_fn=<AddBackward0>)\n",
      "tensor(23999.8379, grad_fn=<AddBackward0>)\n",
      "tensor(24086.7070, grad_fn=<AddBackward0>)\n",
      "tensor(24029.2891, grad_fn=<AddBackward0>)\n",
      "tensor(24053.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24022.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24050.3633, grad_fn=<AddBackward0>)\n",
      "tensor(23925.1992, grad_fn=<AddBackward0>)\n",
      "tensor(24079.8086, grad_fn=<AddBackward0>)\n",
      "tensor(24055.8281, grad_fn=<AddBackward0>)\n",
      "tensor(23997.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24002.3926, grad_fn=<AddBackward0>)\n",
      "tensor(24028.2109, grad_fn=<AddBackward0>)\n",
      "tensor(23953.5664, grad_fn=<AddBackward0>)\n",
      "tensor(24065.2539, grad_fn=<AddBackward0>)\n",
      "tensor(23928.0859, grad_fn=<AddBackward0>)\n",
      "tensor(24059.1797, grad_fn=<AddBackward0>)\n",
      "tensor(24056.3652, grad_fn=<AddBackward0>)\n",
      "tensor(24000.4219, grad_fn=<AddBackward0>)\n",
      "tensor(23960.2324, grad_fn=<AddBackward0>)\n",
      "tensor(24080.2930, grad_fn=<AddBackward0>)\n",
      "tensor(24043.0312, grad_fn=<AddBackward0>)\n",
      "tensor(23946.1914, grad_fn=<AddBackward0>)\n",
      "tensor(24056.3496, grad_fn=<AddBackward0>)\n",
      "tensor(24041.3320, grad_fn=<AddBackward0>)\n",
      "tensor(23991.5234, grad_fn=<AddBackward0>)\n",
      "tensor(24047.4434, grad_fn=<AddBackward0>)\n",
      "tensor(23968.3125, grad_fn=<AddBackward0>)\n",
      "tensor(24039.4414, grad_fn=<AddBackward0>)\n",
      "tensor(24087.9062, grad_fn=<AddBackward0>)\n",
      "tensor(23958.2285, grad_fn=<AddBackward0>)\n",
      "tensor(24036.3457, grad_fn=<AddBackward0>)\n",
      "tensor(24060.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23967.2422, grad_fn=<AddBackward0>)\n",
      "tensor(23937.7969, grad_fn=<AddBackward0>)\n",
      "tensor(23997.0254, grad_fn=<AddBackward0>)\n",
      "tensor(23942.9297, grad_fn=<AddBackward0>)\n",
      "tensor(23970.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24081.4180, grad_fn=<AddBackward0>)\n",
      "tensor(24073.9512, grad_fn=<AddBackward0>)\n",
      "tensor(23945.9004, grad_fn=<AddBackward0>)\n",
      "tensor(24039.9785, grad_fn=<AddBackward0>)\n",
      "tensor(23986.8887, grad_fn=<AddBackward0>)\n",
      "tensor(24106.4102, grad_fn=<AddBackward0>)\n",
      "tensor(23956.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24084.0977, grad_fn=<AddBackward0>)\n",
      "tensor(24019.3164, grad_fn=<AddBackward0>)\n",
      "tensor(24093.5566, grad_fn=<AddBackward0>)\n",
      "tensor(24099.9570, grad_fn=<AddBackward0>)\n",
      "tensor(23974.0586, grad_fn=<AddBackward0>)\n",
      "tensor(24098.5703, grad_fn=<AddBackward0>)\n",
      "tensor(24093.5098, grad_fn=<AddBackward0>)\n",
      "tensor(24080.6602, grad_fn=<AddBackward0>)\n",
      "tensor(24100.9414, grad_fn=<AddBackward0>)\n",
      "tensor(23950.2070, grad_fn=<AddBackward0>)\n",
      "tensor(24031.2500, grad_fn=<AddBackward0>)\n",
      "tensor(23935.9668, grad_fn=<AddBackward0>)\n",
      "tensor(24062.4277, grad_fn=<AddBackward0>)\n",
      "tensor(24079.1758, grad_fn=<AddBackward0>)\n",
      "tensor(23950.9375, grad_fn=<AddBackward0>)\n",
      "tensor(24051.8379, grad_fn=<AddBackward0>)\n",
      "tensor(23937.6465, grad_fn=<AddBackward0>)\n",
      "tensor(23937.2891, grad_fn=<AddBackward0>)\n",
      "tensor(23951.6484, grad_fn=<AddBackward0>)\n",
      "tensor(24101.7930, grad_fn=<AddBackward0>)\n",
      "tensor(24050.9844, grad_fn=<AddBackward0>)\n",
      "tensor(23936.9141, grad_fn=<AddBackward0>)\n",
      "tensor(24062.9453, grad_fn=<AddBackward0>)\n",
      "tensor(24051.3496, grad_fn=<AddBackward0>)\n",
      "tensor(23939.4844, grad_fn=<AddBackward0>)\n",
      "tensor(23990.4141, grad_fn=<AddBackward0>)\n",
      "tensor(24069.6562, grad_fn=<AddBackward0>)\n",
      "tensor(24076.8301, grad_fn=<AddBackward0>)\n",
      "tensor(24102.9863, grad_fn=<AddBackward0>)\n",
      "tensor(23952.0059, grad_fn=<AddBackward0>)\n",
      "tensor(24035.9434, grad_fn=<AddBackward0>)\n",
      "tensor(24051.7871, grad_fn=<AddBackward0>)\n",
      "tensor(24096.7910, grad_fn=<AddBackward0>)\n",
      "tensor(24113.2598, grad_fn=<AddBackward0>)\n",
      "tensor(24084.4844, grad_fn=<AddBackward0>)\n",
      "tensor(24010.6602, grad_fn=<AddBackward0>)\n",
      "tensor(23949.8438, grad_fn=<AddBackward0>)\n",
      "tensor(23951.4609, grad_fn=<AddBackward0>)\n",
      "tensor(24065.6758, grad_fn=<AddBackward0>)\n",
      "tensor(23997.4746, grad_fn=<AddBackward0>)\n",
      "tensor(24056.5273, grad_fn=<AddBackward0>)\n",
      "tensor(24030.2637, grad_fn=<AddBackward0>)\n",
      "tensor(23976.7246, grad_fn=<AddBackward0>)\n",
      "tensor(23990.9824, grad_fn=<AddBackward0>)\n",
      "tensor(24082.3848, grad_fn=<AddBackward0>)\n",
      "tensor(24082.0957, grad_fn=<AddBackward0>)\n",
      "tensor(23967.4688, grad_fn=<AddBackward0>)\n",
      "tensor(23944.3281, grad_fn=<AddBackward0>)\n",
      "tensor(24108.7500, grad_fn=<AddBackward0>)\n",
      "tensor(24118.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23993.7676, grad_fn=<AddBackward0>)\n",
      "tensor(24108.8359, grad_fn=<AddBackward0>)\n",
      "tensor(24057.4746, grad_fn=<AddBackward0>)\n",
      "tensor(23991.7891, grad_fn=<AddBackward0>)\n",
      "tensor(24084.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24122.4492, grad_fn=<AddBackward0>)\n",
      "tensor(23956.6875, grad_fn=<AddBackward0>)\n",
      "tensor(23975.8301, grad_fn=<AddBackward0>)\n",
      "tensor(24024.2383, grad_fn=<AddBackward0>)\n",
      "tensor(24108.4336, grad_fn=<AddBackward0>)\n",
      "tensor(24118.2773, grad_fn=<AddBackward0>)\n",
      "tensor(24016.9961, grad_fn=<AddBackward0>)\n",
      "tensor(23948.6172, grad_fn=<AddBackward0>)\n",
      "tensor(24089.2051, grad_fn=<AddBackward0>)\n",
      "tensor(23937.5234, grad_fn=<AddBackward0>)\n",
      "tensor(23995.1895, grad_fn=<AddBackward0>)\n",
      "tensor(23975.4141, grad_fn=<AddBackward0>)\n",
      "tensor(23941.4043, grad_fn=<AddBackward0>)\n",
      "tensor(24128.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23996.2793, grad_fn=<AddBackward0>)\n",
      "tensor(24010.3750, grad_fn=<AddBackward0>)\n",
      "tensor(24121.4199, grad_fn=<AddBackward0>)\n",
      "tensor(24120.7578, grad_fn=<AddBackward0>)\n",
      "tensor(23966.0469, grad_fn=<AddBackward0>)\n",
      "tensor(24105.3496, grad_fn=<AddBackward0>)\n",
      "tensor(24048.4785, grad_fn=<AddBackward0>)\n",
      "tensor(23978.6172, grad_fn=<AddBackward0>)\n",
      "tensor(24019.9883, grad_fn=<AddBackward0>)\n",
      "tensor(24040.0176, grad_fn=<AddBackward0>)\n",
      "tensor(24081.2969, grad_fn=<AddBackward0>)\n",
      "tensor(24120.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23963.0352, grad_fn=<AddBackward0>)\n",
      "tensor(24054.9785, grad_fn=<AddBackward0>)\n",
      "tensor(23974.7207, grad_fn=<AddBackward0>)\n",
      "tensor(24077.5430, grad_fn=<AddBackward0>)\n",
      "tensor(24123.6797, grad_fn=<AddBackward0>)\n",
      "tensor(23958.4590, grad_fn=<AddBackward0>)\n",
      "tensor(23961.5703, grad_fn=<AddBackward0>)\n",
      "tensor(23966.5859, grad_fn=<AddBackward0>)\n",
      "tensor(23978.9277, grad_fn=<AddBackward0>)\n",
      "tensor(23975.1914, grad_fn=<AddBackward0>)\n",
      "tensor(24003.9043, grad_fn=<AddBackward0>)\n",
      "tensor(24118.4180, grad_fn=<AddBackward0>)\n",
      "tensor(24075.8320, grad_fn=<AddBackward0>)\n",
      "tensor(23944.1406, grad_fn=<AddBackward0>)\n",
      "tensor(23984.5371, grad_fn=<AddBackward0>)\n",
      "tensor(24121.5098, grad_fn=<AddBackward0>)\n",
      "tensor(24098.3691, grad_fn=<AddBackward0>)\n",
      "tensor(24067.3867, grad_fn=<AddBackward0>)\n",
      "tensor(23951.7441, grad_fn=<AddBackward0>)\n",
      "tensor(23964.3242, grad_fn=<AddBackward0>)\n",
      "tensor(24123.1035, grad_fn=<AddBackward0>)\n",
      "tensor(24073.7930, grad_fn=<AddBackward0>)\n",
      "tensor(24133.6777, grad_fn=<AddBackward0>)\n",
      "tensor(24045.6680, grad_fn=<AddBackward0>)\n",
      "tensor(24121.3066, grad_fn=<AddBackward0>)\n",
      "tensor(24102.6582, grad_fn=<AddBackward0>)\n",
      "tensor(23982.3027, grad_fn=<AddBackward0>)\n",
      "tensor(24117.0176, grad_fn=<AddBackward0>)\n",
      "tensor(23969.2109, grad_fn=<AddBackward0>)\n",
      "tensor(24057.5312, grad_fn=<AddBackward0>)\n",
      "tensor(24076.8242, grad_fn=<AddBackward0>)\n",
      "tensor(24021.1758, grad_fn=<AddBackward0>)\n",
      "tensor(24048.0410, grad_fn=<AddBackward0>)\n",
      "tensor(24017.5488, grad_fn=<AddBackward0>)\n",
      "tensor(24096.2422, grad_fn=<AddBackward0>)\n",
      "tensor(24105.0117, grad_fn=<AddBackward0>)\n",
      "tensor(23977.5195, grad_fn=<AddBackward0>)\n",
      "tensor(23982.7578, grad_fn=<AddBackward0>)\n",
      "tensor(24141.8613, grad_fn=<AddBackward0>)\n",
      "tensor(24095.1660, grad_fn=<AddBackward0>)\n",
      "tensor(24109.4531, grad_fn=<AddBackward0>)\n",
      "tensor(24130.4141, grad_fn=<AddBackward0>)\n",
      "tensor(23962.7676, grad_fn=<AddBackward0>)\n",
      "tensor(23958.0488, grad_fn=<AddBackward0>)\n",
      "tensor(24005.9707, grad_fn=<AddBackward0>)\n",
      "tensor(23970.9629, grad_fn=<AddBackward0>)\n",
      "tensor(24080.8848, grad_fn=<AddBackward0>)\n",
      "tensor(24074.1680, grad_fn=<AddBackward0>)\n",
      "tensor(24120.9336, grad_fn=<AddBackward0>)\n",
      "tensor(23964.0879, grad_fn=<AddBackward0>)\n",
      "tensor(23978.6797, grad_fn=<AddBackward0>)\n",
      "tensor(24059.8398, grad_fn=<AddBackward0>)\n",
      "tensor(24063.4668, grad_fn=<AddBackward0>)\n",
      "tensor(24054.9902, grad_fn=<AddBackward0>)\n",
      "tensor(24152.2852, grad_fn=<AddBackward0>)\n",
      "tensor(23982.2715, grad_fn=<AddBackward0>)\n",
      "tensor(24143.5273, grad_fn=<AddBackward0>)\n",
      "tensor(24118.4199, grad_fn=<AddBackward0>)\n",
      "tensor(23969.2168, grad_fn=<AddBackward0>)\n",
      "tensor(24114.0645, grad_fn=<AddBackward0>)\n",
      "tensor(24029.3359, grad_fn=<AddBackward0>)\n",
      "tensor(24094.0371, grad_fn=<AddBackward0>)\n",
      "tensor(23954.6406, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23955.4902, grad_fn=<AddBackward0>)\n",
      "tensor(23960.1133, grad_fn=<AddBackward0>)\n",
      "tensor(24001.9453, grad_fn=<AddBackward0>)\n",
      "tensor(23977.4355, grad_fn=<AddBackward0>)\n",
      "tensor(24150.3652, grad_fn=<AddBackward0>)\n",
      "tensor(24033.3750, grad_fn=<AddBackward0>)\n",
      "tensor(24096.2227, grad_fn=<AddBackward0>)\n",
      "tensor(23953.1230, grad_fn=<AddBackward0>)\n",
      "tensor(23952.5293, grad_fn=<AddBackward0>)\n",
      "tensor(23990.2305, grad_fn=<AddBackward0>)\n",
      "tensor(24150.0312, grad_fn=<AddBackward0>)\n",
      "tensor(24142.2070, grad_fn=<AddBackward0>)\n",
      "tensor(24069.4375, grad_fn=<AddBackward0>)\n",
      "tensor(24127.6035, grad_fn=<AddBackward0>)\n",
      "tensor(23986.1133, grad_fn=<AddBackward0>)\n",
      "tensor(24069.8672, grad_fn=<AddBackward0>)\n",
      "tensor(24097.3809, grad_fn=<AddBackward0>)\n",
      "tensor(24041.3223, grad_fn=<AddBackward0>)\n",
      "tensor(23980.4980, grad_fn=<AddBackward0>)\n",
      "tensor(24014.3125, grad_fn=<AddBackward0>)\n",
      "tensor(24000.0625, grad_fn=<AddBackward0>)\n",
      "tensor(24161.4434, grad_fn=<AddBackward0>)\n",
      "tensor(24078.4492, grad_fn=<AddBackward0>)\n",
      "tensor(24105.3613, grad_fn=<AddBackward0>)\n",
      "tensor(24161.7461, grad_fn=<AddBackward0>)\n",
      "tensor(23958.3945, grad_fn=<AddBackward0>)\n",
      "tensor(24013.0996, grad_fn=<AddBackward0>)\n",
      "tensor(24014.5762, grad_fn=<AddBackward0>)\n",
      "tensor(24081.2598, grad_fn=<AddBackward0>)\n",
      "tensor(23990.4180, grad_fn=<AddBackward0>)\n",
      "tensor(24067.7188, grad_fn=<AddBackward0>)\n",
      "tensor(24010.9375, grad_fn=<AddBackward0>)\n",
      "tensor(24059.6953, grad_fn=<AddBackward0>)\n",
      "tensor(24015.1445, grad_fn=<AddBackward0>)\n",
      "tensor(24157.2617, grad_fn=<AddBackward0>)\n",
      "tensor(24077.0254, grad_fn=<AddBackward0>)\n",
      "tensor(24075.3613, grad_fn=<AddBackward0>)\n",
      "tensor(24154.2773, grad_fn=<AddBackward0>)\n",
      "tensor(24069.6738, grad_fn=<AddBackward0>)\n",
      "tensor(24156.4629, grad_fn=<AddBackward0>)\n",
      "tensor(24129.1016, grad_fn=<AddBackward0>)\n",
      "tensor(24148.1973, grad_fn=<AddBackward0>)\n",
      "tensor(24169.1523, grad_fn=<AddBackward0>)\n",
      "tensor(23978.1504, grad_fn=<AddBackward0>)\n",
      "tensor(24040.0664, grad_fn=<AddBackward0>)\n",
      "tensor(24159.2480, grad_fn=<AddBackward0>)\n",
      "tensor(24151.8672, grad_fn=<AddBackward0>)\n",
      "tensor(24048.5664, grad_fn=<AddBackward0>)\n",
      "tensor(23981.8750, grad_fn=<AddBackward0>)\n",
      "tensor(24055.9785, grad_fn=<AddBackward0>)\n",
      "tensor(24134.2617, grad_fn=<AddBackward0>)\n",
      "tensor(23987.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24137.8789, grad_fn=<AddBackward0>)\n",
      "tensor(23980.6699, grad_fn=<AddBackward0>)\n",
      "tensor(24045.7910, grad_fn=<AddBackward0>)\n",
      "tensor(24125.0664, grad_fn=<AddBackward0>)\n",
      "tensor(24168.8887, grad_fn=<AddBackward0>)\n",
      "tensor(24111.6719, grad_fn=<AddBackward0>)\n",
      "tensor(23956.4512, grad_fn=<AddBackward0>)\n",
      "tensor(23981.8496, grad_fn=<AddBackward0>)\n",
      "tensor(23965.3066, grad_fn=<AddBackward0>)\n",
      "tensor(24094.3379, grad_fn=<AddBackward0>)\n",
      "tensor(24092.8906, grad_fn=<AddBackward0>)\n",
      "tensor(24105.3750, grad_fn=<AddBackward0>)\n",
      "tensor(24134.1797, grad_fn=<AddBackward0>)\n",
      "tensor(24169.4902, grad_fn=<AddBackward0>)\n",
      "tensor(24148.8496, grad_fn=<AddBackward0>)\n",
      "tensor(24148.3809, grad_fn=<AddBackward0>)\n",
      "tensor(23952.1602, grad_fn=<AddBackward0>)\n",
      "tensor(24058.0645, grad_fn=<AddBackward0>)\n",
      "tensor(24073.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23956.0195, grad_fn=<AddBackward0>)\n",
      "tensor(24142.3047, grad_fn=<AddBackward0>)\n",
      "tensor(24062.3242, grad_fn=<AddBackward0>)\n",
      "tensor(23991.7031, grad_fn=<AddBackward0>)\n",
      "tensor(24092.8984, grad_fn=<AddBackward0>)\n",
      "tensor(24038.6113, grad_fn=<AddBackward0>)\n",
      "tensor(23959.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24124.0996, grad_fn=<AddBackward0>)\n",
      "tensor(23962.3398, grad_fn=<AddBackward0>)\n",
      "tensor(23973.1172, grad_fn=<AddBackward0>)\n",
      "tensor(24122.0723, grad_fn=<AddBackward0>)\n",
      "tensor(24118.9277, grad_fn=<AddBackward0>)\n",
      "tensor(24160.5410, grad_fn=<AddBackward0>)\n",
      "tensor(23967.4961, grad_fn=<AddBackward0>)\n",
      "tensor(24127.0996, grad_fn=<AddBackward0>)\n",
      "tensor(24143.0840, grad_fn=<AddBackward0>)\n",
      "tensor(24175.6406, grad_fn=<AddBackward0>)\n",
      "tensor(24089.9746, grad_fn=<AddBackward0>)\n",
      "tensor(24111.0371, grad_fn=<AddBackward0>)\n",
      "tensor(24134.1641, grad_fn=<AddBackward0>)\n",
      "tensor(24043.8242, grad_fn=<AddBackward0>)\n",
      "tensor(24174.2324, grad_fn=<AddBackward0>)\n",
      "tensor(23979.5645, grad_fn=<AddBackward0>)\n",
      "tensor(24169.1309, grad_fn=<AddBackward0>)\n",
      "tensor(24146.1016, grad_fn=<AddBackward0>)\n",
      "tensor(24005.1211, grad_fn=<AddBackward0>)\n",
      "tensor(24063.5176, grad_fn=<AddBackward0>)\n",
      "tensor(24098.7617, grad_fn=<AddBackward0>)\n",
      "tensor(24066.4668, grad_fn=<AddBackward0>)\n",
      "tensor(24063.2715, grad_fn=<AddBackward0>)\n",
      "tensor(24146.8438, grad_fn=<AddBackward0>)\n",
      "tensor(24176.9023, grad_fn=<AddBackward0>)\n",
      "tensor(23986.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24142.8418, grad_fn=<AddBackward0>)\n",
      "tensor(24155.7578, grad_fn=<AddBackward0>)\n",
      "tensor(24093.4570, grad_fn=<AddBackward0>)\n",
      "tensor(23995.3574, grad_fn=<AddBackward0>)\n",
      "tensor(23974.9922, grad_fn=<AddBackward0>)\n",
      "tensor(24167.4199, grad_fn=<AddBackward0>)\n",
      "tensor(24142.7949, grad_fn=<AddBackward0>)\n",
      "tensor(23986.4668, grad_fn=<AddBackward0>)\n",
      "tensor(23994.8652, grad_fn=<AddBackward0>)\n",
      "tensor(24004.4980, grad_fn=<AddBackward0>)\n",
      "tensor(23950.8809, grad_fn=<AddBackward0>)\n",
      "tensor(24067.2461, grad_fn=<AddBackward0>)\n",
      "tensor(24142.1602, grad_fn=<AddBackward0>)\n",
      "tensor(23950.6621, grad_fn=<AddBackward0>)\n",
      "tensor(24150.6621, grad_fn=<AddBackward0>)\n",
      "tensor(24145.7305, grad_fn=<AddBackward0>)\n",
      "tensor(23988.1758, grad_fn=<AddBackward0>)\n",
      "tensor(24004.7930, grad_fn=<AddBackward0>)\n",
      "tensor(24078.5996, grad_fn=<AddBackward0>)\n",
      "tensor(23983.8594, grad_fn=<AddBackward0>)\n",
      "tensor(23954.4355, grad_fn=<AddBackward0>)\n",
      "tensor(23983.0840, grad_fn=<AddBackward0>)\n",
      "tensor(24131.1992, grad_fn=<AddBackward0>)\n",
      "tensor(24014.2871, grad_fn=<AddBackward0>)\n",
      "tensor(24184.3516, grad_fn=<AddBackward0>)\n",
      "tensor(24130.7871, grad_fn=<AddBackward0>)\n",
      "tensor(24074.4922, grad_fn=<AddBackward0>)\n",
      "tensor(24048.8379, grad_fn=<AddBackward0>)\n",
      "tensor(24087.2539, grad_fn=<AddBackward0>)\n",
      "tensor(23998.7227, grad_fn=<AddBackward0>)\n",
      "tensor(24148.1367, grad_fn=<AddBackward0>)\n",
      "tensor(24092.3242, grad_fn=<AddBackward0>)\n",
      "tensor(24090.2969, grad_fn=<AddBackward0>)\n",
      "tensor(23975.8652, grad_fn=<AddBackward0>)\n",
      "tensor(24139.1738, grad_fn=<AddBackward0>)\n",
      "tensor(24151.2461, grad_fn=<AddBackward0>)\n",
      "tensor(24042.4492, grad_fn=<AddBackward0>)\n",
      "tensor(24156.2578, grad_fn=<AddBackward0>)\n",
      "tensor(24191.0234, grad_fn=<AddBackward0>)\n",
      "tensor(24119.8145, grad_fn=<AddBackward0>)\n",
      "tensor(24195.5039, grad_fn=<AddBackward0>)\n",
      "tensor(24176.0039, grad_fn=<AddBackward0>)\n",
      "tensor(24047.1543, grad_fn=<AddBackward0>)\n",
      "tensor(24186.4941, grad_fn=<AddBackward0>)\n",
      "tensor(24112.6504, grad_fn=<AddBackward0>)\n",
      "tensor(23991.3574, grad_fn=<AddBackward0>)\n",
      "tensor(23994.8535, grad_fn=<AddBackward0>)\n",
      "tensor(24103., grad_fn=<AddBackward0>)\n",
      "tensor(24153.6836, grad_fn=<AddBackward0>)\n",
      "tensor(23990.1973, grad_fn=<AddBackward0>)\n",
      "tensor(23979.4727, grad_fn=<AddBackward0>)\n",
      "tensor(23968.4121, grad_fn=<AddBackward0>)\n",
      "tensor(23967.9824, grad_fn=<AddBackward0>)\n",
      "tensor(24200.9668, grad_fn=<AddBackward0>)\n",
      "tensor(24122.8203, grad_fn=<AddBackward0>)\n",
      "tensor(24045.2402, grad_fn=<AddBackward0>)\n",
      "tensor(23963.7793, grad_fn=<AddBackward0>)\n",
      "tensor(24092.4570, grad_fn=<AddBackward0>)\n",
      "tensor(24073.4961, grad_fn=<AddBackward0>)\n",
      "tensor(24014.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24014.9453, grad_fn=<AddBackward0>)\n",
      "tensor(24075.1387, grad_fn=<AddBackward0>)\n",
      "tensor(24101.7910, grad_fn=<AddBackward0>)\n",
      "tensor(23991.6133, grad_fn=<AddBackward0>)\n",
      "tensor(23976.8770, grad_fn=<AddBackward0>)\n",
      "tensor(24022.8223, grad_fn=<AddBackward0>)\n",
      "tensor(24192.6289, grad_fn=<AddBackward0>)\n",
      "tensor(23970.4199, grad_fn=<AddBackward0>)\n",
      "tensor(24006.4609, grad_fn=<AddBackward0>)\n",
      "tensor(24136.9922, grad_fn=<AddBackward0>)\n",
      "tensor(23996.5273, grad_fn=<AddBackward0>)\n",
      "tensor(24084.8418, grad_fn=<AddBackward0>)\n",
      "tensor(24168.1875, grad_fn=<AddBackward0>)\n",
      "tensor(24061.5312, grad_fn=<AddBackward0>)\n",
      "tensor(24136.6328, grad_fn=<AddBackward0>)\n",
      "tensor(23995.8418, grad_fn=<AddBackward0>)\n",
      "tensor(23994.3320, grad_fn=<AddBackward0>)\n",
      "tensor(24202.6055, grad_fn=<AddBackward0>)\n",
      "tensor(24154.7988, grad_fn=<AddBackward0>)\n",
      "tensor(24147.1855, grad_fn=<AddBackward0>)\n",
      "tensor(23967.1406, grad_fn=<AddBackward0>)\n",
      "tensor(23992.1426, grad_fn=<AddBackward0>)\n",
      "tensor(24001.1250, grad_fn=<AddBackward0>)\n",
      "tensor(24143.6016, grad_fn=<AddBackward0>)\n",
      "tensor(23981.4395, grad_fn=<AddBackward0>)\n",
      "tensor(24177.6816, grad_fn=<AddBackward0>)\n",
      "tensor(23997.5508, grad_fn=<AddBackward0>)\n",
      "tensor(23988.3125, grad_fn=<AddBackward0>)\n",
      "tensor(24210.4668, grad_fn=<AddBackward0>)\n",
      "tensor(24181.5625, grad_fn=<AddBackward0>)\n",
      "tensor(23996.3789, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24193.9863, grad_fn=<AddBackward0>)\n",
      "tensor(24007.8828, grad_fn=<AddBackward0>)\n",
      "tensor(24165.4160, grad_fn=<AddBackward0>)\n",
      "tensor(23984.4102, grad_fn=<AddBackward0>)\n",
      "tensor(23954.4883, grad_fn=<AddBackward0>)\n",
      "tensor(24192.7812, grad_fn=<AddBackward0>)\n",
      "tensor(23996.6465, grad_fn=<AddBackward0>)\n",
      "tensor(24199.8848, grad_fn=<AddBackward0>)\n",
      "tensor(24008.8984, grad_fn=<AddBackward0>)\n",
      "tensor(24154.1191, grad_fn=<AddBackward0>)\n",
      "tensor(24176.5410, grad_fn=<AddBackward0>)\n",
      "tensor(24169.6895, grad_fn=<AddBackward0>)\n",
      "tensor(24097.5215, grad_fn=<AddBackward0>)\n",
      "tensor(24003.3164, grad_fn=<AddBackward0>)\n",
      "tensor(24195.5078, grad_fn=<AddBackward0>)\n",
      "tensor(24060.3574, grad_fn=<AddBackward0>)\n",
      "tensor(24110.7129, grad_fn=<AddBackward0>)\n",
      "tensor(23983.1875, grad_fn=<AddBackward0>)\n",
      "tensor(23981.8301, grad_fn=<AddBackward0>)\n",
      "tensor(24194.2266, grad_fn=<AddBackward0>)\n",
      "tensor(24100.0781, grad_fn=<AddBackward0>)\n",
      "tensor(24152.6953, grad_fn=<AddBackward0>)\n",
      "tensor(24039.8477, grad_fn=<AddBackward0>)\n",
      "tensor(23954.3027, grad_fn=<AddBackward0>)\n",
      "tensor(24057.9707, grad_fn=<AddBackward0>)\n",
      "tensor(24145.3262, grad_fn=<AddBackward0>)\n",
      "tensor(23973.8438, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#initial = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0)]\n",
    "\n",
    "initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.0), (0.0, 2.1)]\n",
    "\n",
    "#initial = torch.rand (15, 2)\n",
    "\n",
    "#initial = [(0.0, 0.0), (1.0, 0.0), (2.0, 1.5)]\n",
    "\n",
    "points = torch.tensor(initial, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([points], lr = 0.001)\n",
    "tri = Delaunay (initial)\n",
    "simplices = tri.simplices\n",
    "E, E_b = find_E_Eb (initial, simplices)\n",
    "\n",
    "for _ in range (1000):\n",
    "    L = calc_L (points, simplices)\n",
    "    A = calc_A (simplices, L, len (points))\n",
    "    W = calc_W (E, E_b, A, L, simplices)\n",
    "    pen = rho (points, L, E_b, simplices)\n",
    "    \n",
    "    current_eigen = find_eigenvalues(W, A)\n",
    "    \n",
    "    #loss =   weighted_norm(current_eigen, mu)+pen# calculate loss\n",
    "    loss =   weighted_norm(current_eigen, mu)+pen# calculate loss\n",
    "    #print (mu)\n",
    "    optimizer.zero_grad()  # clear previous gradients\n",
    "    loss.backward()        # compute gradients of all variables wrt loss\n",
    "\n",
    "    optimizer.step()\n",
    "    #print (current_eigen)\n",
    "    print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_mesh (mesh):\n",
    "    plt.plot (mesh [:, 0], mesh [:, 1], 'o')\n",
    "    plt.show()\n",
    "\n",
    "def generate_circle (x, y, r, num, num_interior=0):\n",
    "    circle = np.zeros ((num + num_interior, 2), np.float64)\n",
    "    \n",
    "    for i in range (num):\n",
    "        angle = math.pi * 2 / num * i\n",
    "        \n",
    "        circle [i, 0] = x + r * math.cos (angle)\n",
    "        circle [i, 1] = y + r * math.sin (angle)\n",
    "    \n",
    "    for i in range (num_interior):\n",
    "        px = 0\n",
    "        py = 0\n",
    "        \n",
    "        while (True):\n",
    "            px = np.random.rand (1)\n",
    "            py = np.random.rand (1)\n",
    "            \n",
    "            if ((px - 0.5)**2 + (py - 0.5)**2 < 0.25):\n",
    "                break\n",
    "        \n",
    "        px = x + px * 2 * r - r\n",
    "        py = y + py * 2 * r - r\n",
    "        \n",
    "        circle [num + i, 0] = px\n",
    "        circle [num + i, 1] = py\n",
    "\n",
    "    return circle\n",
    "\n",
    "def generate_random_mesh (num):\n",
    "    mesh = np.random.rand (num, 2)\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "circle = generate_circle (0, 1, 1, 20, num_interior=40)\n",
    "plot_mesh (circle)\n",
    "\n",
    "rand_mesh = generate_random_mesh (15)\n",
    "plot_mesh (rand_mesh)\n",
    "\n",
    "#Немного о том, почему функция генерации кружочка именно такая.\n",
    "#В ней отдельно задается количество внешних точек и отдельно количество внутренних.\n",
    "#Это нужно, чтобы после генерации рандомного меша получить количество граничных точек\n",
    "#в нем и создать кружочек с таким же количеством граничных точек. Это будет означать,\n",
    "#что количество граничных ребер в множествах тоже совпадает. Насколько я понимаю, это\n",
    "#необходимо, потому что если рандомный меш состоит из четырех точек - треугольника и\n",
    "#одной внутренней, то приближать его, начиная с квадрата, было бы странно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
